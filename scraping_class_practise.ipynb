{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "021e7ee2-90e1-4650-875b-166cc9503b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scrapy in c:\\users\\birendra\\anaconda3\\lib\\site-packages (2.11.1)\n",
      "Requirement already satisfied: Twisted>=18.9.0 in c:\\users\\birendra\\anaconda3\\lib\\site-packages (from scrapy) (23.10.0)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\birendra\\anaconda3\\lib\\site-packages (from scrapy) (43.0.0)\n",
      "Requirement already satisfied: cssselect>=0.9.1 in c:\\users\\birendra\\anaconda3\\lib\\site-packages (from scrapy) (1.2.0)\n",
      "Requirement already satisfied: itemloaders>=1.0.1 in c:\\users\\birendra\\anaconda3\\lib\\site-packages (from scrapy) (1.1.0)\n",
      "Requirement already satisfied: parsel>=1.5.0 in c:\\users\\birendra\\anaconda3\\lib\\site-packages (from scrapy) (1.8.1)\n",
      "Requirement already satisfied: pyOpenSSL>=21.0.0 in c:\\users\\birendra\\anaconda3\\lib\\site-packages (from scrapy) (24.2.1)\n",
      "Requirement already satisfied: queuelib>=1.4.2 in c:\\users\\birendra\\anaconda3\\lib\\site-packages (from scrapy) (1.6.2)\n",
      "Requirement already satisfied: service-identity>=18.1.0 in c:\\users\\birendra\\anaconda3\\lib\\site-packages (from scrapy) (18.1.0)\n",
      "Requirement already satisfied: w3lib>=1.17.0 in c:\\users\\birendra\\anaconda3\\lib\\site-packages (from scrapy) (2.1.2)\n",
      "Requirement already satisfied: zope.interface>=5.1.0 in c:\\users\\birendra\\anaconda3\\lib\\site-packages (from scrapy) (5.4.0)\n",
      "Requirement already satisfied: protego>=0.1.15 in c:\\users\\birendra\\anaconda3\\lib\\site-packages (from scrapy) (0.1.16)\n",
      "Requirement already satisfied: itemadapter>=0.1.0 in c:\\users\\birendra\\anaconda3\\lib\\site-packages (from scrapy) (0.3.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\birendra\\anaconda3\\lib\\site-packages (from scrapy) (75.1.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\birendra\\anaconda3\\lib\\site-packages (from scrapy) (24.1)\n",
      "Requirement already satisfied: tldextract in c:\\users\\birendra\\anaconda3\\lib\\site-packages (from scrapy) (5.1.2)\n",
      "Requirement already satisfied: lxml>=4.4.1 in c:\\users\\birendra\\anaconda3\\lib\\site-packages (from scrapy) (5.2.1)\n",
      "Requirement already satisfied: PyDispatcher>=2.0.5 in c:\\users\\birendra\\anaconda3\\lib\\site-packages (from scrapy) (2.0.5)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\birendra\\anaconda3\\lib\\site-packages (from cryptography>=36.0.0->scrapy) (1.17.1)\n",
      "Requirement already satisfied: jmespath>=0.9.5 in c:\\users\\birendra\\anaconda3\\lib\\site-packages (from itemloaders>=1.0.1->scrapy) (1.0.1)\n",
      "Requirement already satisfied: six in c:\\users\\birendra\\anaconda3\\lib\\site-packages (from protego>=0.1.15->scrapy) (1.16.0)\n",
      "Requirement already satisfied: attrs>=16.0.0 in c:\\users\\birendra\\anaconda3\\lib\\site-packages (from service-identity>=18.1.0->scrapy) (23.1.0)\n",
      "Requirement already satisfied: pyasn1-modules in c:\\users\\birendra\\anaconda3\\lib\\site-packages (from service-identity>=18.1.0->scrapy) (0.2.8)\n",
      "Requirement already satisfied: pyasn1 in c:\\users\\birendra\\anaconda3\\lib\\site-packages (from service-identity>=18.1.0->scrapy) (0.4.8)\n",
      "Requirement already satisfied: automat>=0.8.0 in c:\\users\\birendra\\anaconda3\\lib\\site-packages (from Twisted>=18.9.0->scrapy) (20.2.0)\n",
      "Requirement already satisfied: constantly>=15.1 in c:\\users\\birendra\\anaconda3\\lib\\site-packages (from Twisted>=18.9.0->scrapy) (23.10.4)\n",
      "Requirement already satisfied: hyperlink>=17.1.1 in c:\\users\\birendra\\anaconda3\\lib\\site-packages (from Twisted>=18.9.0->scrapy) (21.0.0)\n",
      "Requirement already satisfied: incremental>=22.10.0 in c:\\users\\birendra\\anaconda3\\lib\\site-packages (from Twisted>=18.9.0->scrapy) (22.10.0)\n",
      "Requirement already satisfied: twisted-iocpsupport<2,>=1.0.2 in c:\\users\\birendra\\anaconda3\\lib\\site-packages (from Twisted>=18.9.0->scrapy) (1.0.2)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\birendra\\anaconda3\\lib\\site-packages (from Twisted>=18.9.0->scrapy) (4.11.0)\n",
      "Requirement already satisfied: idna in c:\\users\\birendra\\anaconda3\\lib\\site-packages (from tldextract->scrapy) (3.7)\n",
      "Requirement already satisfied: requests>=2.1.0 in c:\\users\\birendra\\anaconda3\\lib\\site-packages (from tldextract->scrapy) (2.32.3)\n",
      "Requirement already satisfied: requests-file>=1.4 in c:\\users\\birendra\\anaconda3\\lib\\site-packages (from tldextract->scrapy) (1.5.1)\n",
      "Requirement already satisfied: filelock>=3.0.8 in c:\\users\\birendra\\anaconda3\\lib\\site-packages (from tldextract->scrapy) (3.13.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\birendra\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->scrapy) (2.21)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\birendra\\anaconda3\\lib\\site-packages (from requests>=2.1.0->tldextract->scrapy) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\birendra\\anaconda3\\lib\\site-packages (from requests>=2.1.0->tldextract->scrapy) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\birendra\\anaconda3\\lib\\site-packages (from requests>=2.1.0->tldextract->scrapy) (2025.4.26)\n"
     ]
    }
   ],
   "source": [
    "!pip install scrapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9d3e928-ab4c-42e3-b30a-f9717b10f929",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f30ca8e2-b259-457c-b48e-e15b3218d0ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project found in directory\n",
      "Directories: ['project1']\n",
      "Files: []\n",
      "Directories: ['project1']\n",
      "Files: ['scrapy.cfg']\n",
      "Directories: ['spiders']\n",
      "Files: ['items.py', 'middlewares.py', 'pipelines.py', 'settings.py', '__init__.py']\n",
      "Directories: []\n",
      "Files: ['__init__.py']\n"
     ]
    }
   ],
   "source": [
    "#project_dir = 'scrapy_project'\n",
    "desktop_path = os.path.join(os.path.expanduser(\"~\"),\"Desktop\")\n",
    "project_dir = os.path.join(desktop_path, 'scrappy')\n",
    "if os.path.exists(project_dir):\n",
    "  print(\"project found in directory\")\n",
    "  for root, dirs, files in os.walk(project_dir):\n",
    "   print(\"Directories:\", dirs)\n",
    "   print(\"Files:\", files)\n",
    "else:\n",
    "    print(\"project not found in directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20b772f1-a98c-4b33-849e-58929602ebaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = \"scrapy_project5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa456070-43b3-4cc8-9546-cfbdcf59fdc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(f'scrapy startproject {project_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ec261e5-68f9-4ca9-bc1e-3b12e9ce91c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scrapy.cfg', 'scrapy_project5']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(project_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "baf87da4-3845-4ca6-a4e5-7b5370855194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the spider code as a string\n",
    "\n",
    "spider_code = \"\"\"\n",
    "\n",
    "import scrapy\n",
    " \n",
    "class MySpider(scrapy.Spider):\n",
    "\n",
    "    name = 'my_spider'\n",
    "\n",
    "    start_urls = ['http://quotes.toscrape.com']\n",
    " \n",
    "    def parse(self, response):\n",
    "\n",
    "        for quote in response.css('div.quote'):\n",
    "\n",
    "            yield {\n",
    "\n",
    "                'text': quote.css('span.text::text').get(),\n",
    "\n",
    "                'author': quote.css('small.author::text').get(),\n",
    "\n",
    "                'tags': quote.css('div.tags a.tag::text').getall(),\n",
    "\n",
    "            }\n",
    "\n",
    "        next_page = response.css('li.next a::attr(href)').get()\n",
    "\n",
    "        if next_page:\n",
    "\n",
    "            yield response.follow(next_page, self.parse)\n",
    "\n",
    "\"\"\"\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5e0a65c-4010-475e-958d-37825d519a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scrapy.cfg', 'scrapy_project5']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_name = \"scrapy_project5\"\n",
    "os.listdir(project_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1733f3d-6c46-4603-b592-b8fe25a32681",
   "metadata": {},
   "outputs": [],
   "source": [
    "spider_file_path = os.path.join(project_name,project_name, \"spiders\", \"my_spider.py\")\n",
    "\n",
    "with open(spider_file_path, 'w') as f:\n",
    "    f.write(spider_code)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8eb29381-922f-42d3-913c-9929487bbc3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'scrapy_project5\\\\out.json'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "project_name= \"scrapy_project5\"\n",
    "output_file = os.path.join(project_name, \"out.json\")\n",
    "output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78e31c09-afb3-4ef3-b4f0-930c672acca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['scrapy', 'crawl', 'my_spider', '-o', 'scrapy_project5\\\\out.json', '-t', 'json'], returncode=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run([\n",
    "    'scrapy',\n",
    "    'crawl',\n",
    "    'my_spider',\n",
    "    '-o',\n",
    "    output_file,\n",
    "    '-t',\n",
    "    'json'\n",
    "], cwd=project_name)\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2678184-ee5e-41be-89a4-92cee3eda7a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'scrapy_project5\\\\scrapy_project5\\\\out.json'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import json\n",
    " \n",
    "json_file_path = os.path.join(project_name, project_name, 'out.json') \n",
    "json_file_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e5851e4-578e-42f4-ae86-6e498930f0ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Extra data: line 3 column 2 (char 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m data \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(json_file_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m----> 3\u001b[0m     data\u001b[38;5;241m=\u001b[39mjson\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m      7\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(df)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\json\\__init__.py:293\u001b[0m, in \u001b[0;36mload\u001b[1;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(fp, \u001b[38;5;241m*\u001b[39m, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    275\u001b[0m         parse_int\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_constant\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_pairs_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[0;32m    276\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;124;03m    a JSON document) to a Python object.\u001b[39;00m\n\u001b[0;32m    278\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;124;03m    kwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[0;32m    292\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loads(fp\u001b[38;5;241m.\u001b[39mread(),\n\u001b[0;32m    294\u001b[0m         \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcls\u001b[39m, object_hook\u001b[38;5;241m=\u001b[39mobject_hook,\n\u001b[0;32m    295\u001b[0m         parse_float\u001b[38;5;241m=\u001b[39mparse_float, parse_int\u001b[38;5;241m=\u001b[39mparse_int,\n\u001b[0;32m    296\u001b[0m         parse_constant\u001b[38;5;241m=\u001b[39mparse_constant, object_pairs_hook\u001b[38;5;241m=\u001b[39mobject_pairs_hook, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _default_decoder\u001b[38;5;241m.\u001b[39mdecode(s)\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\json\\decoder.py:340\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    338\u001b[0m end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[0;32m    339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n\u001b[1;32m--> 340\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtra data\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, end)\n\u001b[0;32m    341\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Extra data: line 3 column 2 (char 4)"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "with open(json_file_path, 'r') as f:\n",
    "    data=json.load(f)\n",
    "\n",
    "      \n",
    " \n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdf2200-1778-4b88-9817-ac89c9000b4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
